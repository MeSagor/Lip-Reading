{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 16:33:39.646404: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/SAGOR/Unknown/AI_Works/Lip_Reading_code/lip_venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " time_distributed (TimeDist  (None, 120, 2, 3, 960)    2996064   Y          \n",
      " ributed)                                                                   \n",
      "                                                                            \n",
      " time_distributed_1 (TimeDi  (None, 120, 5760)         0         Y          \n",
      " stributed)                                                                 \n",
      "                                                                            \n",
      " bidirectional (Bidirection  (None, 120, 512)          1232281   Y          \n",
      " al)                                                   6                    \n",
      "                                                                            \n",
      " dropout (Dropout)           (None, 120, 512)          0         Y          \n",
      "                                                                            \n",
      " bidirectional_1 (Bidirecti  (None, 120, 512)          1574912   Y          \n",
      " onal)                                                                      \n",
      "                                                                            \n",
      " dropout_1 (Dropout)         (None, 120, 512)          0         Y          \n",
      "                                                                            \n",
      " dense (Dense)               (None, 120, 40)           20520     Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 16914312 (64.52 MB)\n",
      "Trainable params: 16889912 (64.43 MB)\n",
      "Non-trainable params: 24400 (95.31 KB)\n",
      "____________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv3D, Activation, MaxPooling3D, TimeDistributed, Flatten, Bidirectional, LSTM, Dropout, Dense, Input\n",
    "\n",
    "# Define constants\n",
    "frame_rate = 120  # Number of frames per video\n",
    "input_height = 60  # Height of each frame\n",
    "input_width = 80  # Width of each frame\n",
    "num_channels = 1  # Grayscale\n",
    "vocab_size = 40  # Assuming char_to_num is defined\n",
    "\n",
    "# Define the feature extractor (MobileNetV3 Large)\n",
    "mobilenetv3 = MobileNetV3Large(\n",
    "    input_shape=(input_height, input_width, num_channels),\n",
    "    include_top=False,\n",
    "    weights=None  # Use pretrained weights if available\n",
    ")\n",
    "\n",
    "# Adjust MobileNetV3 to take grayscale images by modifying the input layer\n",
    "input_layer = Input(shape=(input_height, input_width, num_channels))\n",
    "mobilenetv3_output = mobilenetv3(input_layer)\n",
    "feature_extractor = Model(inputs=input_layer, outputs=mobilenetv3_output)\n",
    "\n",
    "# # Freeze the feature extractor layers if necessary\n",
    "# for layer in feature_extractor.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# Build the full model\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(feature_extractor, input_shape=(frame_rate, input_height, input_width, num_channels)))\n",
    "\n",
    "# Adding the LSTM part\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Bidirectional(LSTM(256, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Bidirectional(LSTM(256, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(vocab_size, kernel_initializer='he_normal', activation='softmax'))\n",
    "\n",
    "# Summary of the model\n",
    "model.summary(show_trainable=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " time_distributed_2 (TimeDi  (None, 120, 1, 2, 512)    1471353   Y          \n",
      " stributed)                                            6                    \n",
      "                                                                            \n",
      " time_distributed_3 (TimeDi  (None, 120, 1024)         0         Y          \n",
      " stributed)                                                                 \n",
      "                                                                            \n",
      " bidirectional_2 (Bidirecti  (None, 120, 512)          2623488   Y          \n",
      " onal)                                                                      \n",
      "                                                                            \n",
      " dropout_2 (Dropout)         (None, 120, 512)          0         Y          \n",
      "                                                                            \n",
      " bidirectional_3 (Bidirecti  (None, 120, 512)          1574912   Y          \n",
      " onal)                                                                      \n",
      "                                                                            \n",
      " dropout_3 (Dropout)         (None, 120, 512)          0         Y          \n",
      "                                                                            \n",
      " dense_1 (Dense)             (None, 120, 40)           20520     Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 18932456 (72.22 MB)\n",
      "Trainable params: 18932456 (72.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "____________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import TimeDistributed, Flatten, Bidirectional, LSTM, Dropout, Dense, Input\n",
    "\n",
    "# Define constants\n",
    "frame_rate = 120  # Number of frames per video\n",
    "input_height = 60  # Height of each frame\n",
    "input_width = 80  # Width of each frame\n",
    "num_channels = 1  # Grayscale\n",
    "vocab_size = 40  # Assuming char_to_num is defined\n",
    "\n",
    "# Define the feature extractor (VGG16)\n",
    "vgg16 = VGG16(\n",
    "    input_shape=(input_height, input_width, num_channels),\n",
    "    include_top=False,\n",
    "    weights=None  # Use pretrained weights if available\n",
    ")\n",
    "\n",
    "# Adjust VGG16 to take grayscale images by modifying the input layer\n",
    "input_layer = Input(shape=(input_height, input_width, num_channels))\n",
    "vgg16_output = vgg16(input_layer)\n",
    "feature_extractor = Model(inputs=input_layer, outputs=vgg16_output)\n",
    "\n",
    "# # Freeze the feature extractor layers if necessary\n",
    "# for layer in feature_extractor.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# Build the full model\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(feature_extractor, input_shape=(frame_rate, input_height, input_width, num_channels)))\n",
    "\n",
    "# Adding the LSTM part\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Bidirectional(LSTM(256, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Bidirectional(LSTM(256, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(vocab_size, kernel_initializer='he_normal', activation='softmax'))\n",
    "\n",
    "# Summary of the model\n",
    "model.summary(show_trainable=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " time_distributed_4 (TimeDi  (None, 120, 1, 1, 2048)   2180220   Y          \n",
      " stributed)                                            8                    \n",
      "                                                                            \n",
      " time_distributed_5 (TimeDi  (None, 120, 2048)         0         Y          \n",
      " stributed)                                                                 \n",
      "                                                                            \n",
      " bidirectional_4 (Bidirecti  (None, 120, 512)          4720640   Y          \n",
      " onal)                                                                      \n",
      "                                                                            \n",
      " dropout_4 (Dropout)         (None, 120, 512)          0         Y          \n",
      "                                                                            \n",
      " bidirectional_5 (Bidirecti  (None, 120, 512)          1574912   Y          \n",
      " onal)                                                                      \n",
      "                                                                            \n",
      " dropout_5 (Dropout)         (None, 120, 512)          0         Y          \n",
      "                                                                            \n",
      " dense_2 (Dense)             (None, 120, 40)           20520     Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 28118280 (107.26 MB)\n",
      "Trainable params: 28083848 (107.13 MB)\n",
      "Non-trainable params: 34432 (134.50 KB)\n",
      "____________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import TimeDistributed, Flatten, Bidirectional, LSTM, Dropout, Dense, Input\n",
    "\n",
    "# Define constants\n",
    "frame_rate = 120  # Number of frames per video\n",
    "input_height = 75  # Height of each frame (minimum required by InceptionV3)\n",
    "input_width = 75  # Width of each frame (minimum required by InceptionV3)\n",
    "num_channels = 1  # Grayscale\n",
    "vocab_size = 40  # Assuming char_to_num is defined\n",
    "\n",
    "# Define the feature extractor (InceptionV3)\n",
    "inceptionv3 = InceptionV3(\n",
    "    input_shape=(input_height, input_width, num_channels),\n",
    "    include_top=False,\n",
    "    weights=None  # Use pretrained weights if available\n",
    ")\n",
    "\n",
    "# Adjust InceptionV3 to take grayscale images by modifying the input layer\n",
    "input_layer = Input(shape=(input_height, input_width, num_channels))\n",
    "inceptionv3_output = inceptionv3(input_layer)\n",
    "feature_extractor = Model(inputs=input_layer, outputs=inceptionv3_output)\n",
    "\n",
    "# # Freeze the feature extractor layers if necessary\n",
    "# for layer in feature_extractor.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# Build the full model\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(feature_extractor, input_shape=(frame_rate, input_height, input_width, num_channels)))\n",
    "\n",
    "# Adding the LSTM part\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Bidirectional(LSTM(256, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Bidirectional(LSTM(256, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(vocab_size, kernel_initializer='he_normal', activation='softmax'))\n",
    "\n",
    "# Summary of the model\n",
    "model.summary(show_trainable=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lip_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
